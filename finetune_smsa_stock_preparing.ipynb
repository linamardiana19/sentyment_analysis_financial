{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning & Preparing dataset sentiment\n",
    "Emot is a Emotion Recognition dataset with 5 possible labels: `sadness`, `anger`, `trust`, `fear`, `joy`, 'anticipation', 'surprise', 'disgust'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append('../')\n",
    "os.chdir('../') \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path1 = './dataset/dataset_smsa_stok/IDSMSA.csv'\n",
    "# dataset_path2 = 'dataset/news_bri/train.jsonl'\n",
    "# dataset_path2 = 'dataset/news_bri/test.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(os.path.exists(dataset_path1))  # harus True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = pd.read_csv(dataset_path1)\n",
    "# dataset2 = pd.read_json(dataset_path2, lines=True)\n",
    "# dataset3 = pd.read_json(dataset_path3, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3288 entries, 0 to 3287\n",
      "Data columns (total 8 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   Tweet Date           3288 non-null   object\n",
      " 1   Sentence             3288 non-null   object\n",
      " 2   Quote Count          3288 non-null   int64 \n",
      " 3   Reply Count          3288 non-null   int64 \n",
      " 4   Retweet Count        3288 non-null   int64 \n",
      " 5   Favorite Count       3288 non-null   int64 \n",
      " 6   Sentiment            3288 non-null   object\n",
      " 7   English Translation  3288 non-null   object\n",
      "dtypes: int64(4), object(4)\n",
      "memory usage: 205.6+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet Date</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Quote Count</th>\n",
       "      <th>Reply Count</th>\n",
       "      <th>Retweet Count</th>\n",
       "      <th>Favorite Count</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>English Translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thu Feb 29 11:21:27 +0000 2024</td>\n",
       "      <td>Gk muluk muluk, 100,000 lot saham BBCA aja</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Not too ambitious, just 100,000 lots of BBCA s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thu Feb 29 10:11:05 +0000 2024</td>\n",
       "      <td>BCA Expoversary 2024 menawarkan promo suku bun...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>BCA Expoversary 2024 offers special interest r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Tweet Date  \\\n",
       "0  Thu Feb 29 11:21:27 +0000 2024   \n",
       "1  Thu Feb 29 10:11:05 +0000 2024   \n",
       "\n",
       "                                            Sentence  Quote Count  \\\n",
       "0         Gk muluk muluk, 100,000 lot saham BBCA aja            0   \n",
       "1  BCA Expoversary 2024 menawarkan promo suku bun...            0   \n",
       "\n",
       "   Reply Count  Retweet Count  Favorite Count Sentiment  \\\n",
       "0            0              0               0  Positive   \n",
       "1            0              0               0   Neutral   \n",
       "\n",
       "                                 English Translation  \n",
       "0  Not too ambitious, just 100,000 lots of BBCA s...  \n",
       "1  BCA Expoversary 2024 offers special interest r...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment\n",
       "Positive    1769\n",
       "Negative     786\n",
       "Neutral      733\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset1.Sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ubah ke datetime\n",
    "dataset1['Tweet Date'] = pd.to_datetime(dataset1['Tweet Date'], format='%a %b %d %H:%M:%S %z %Y')\n",
    "\n",
    "# Buat kolom baru berisi Tanggal-Bulan-Tahun (bisa dalam string atau datetime)\n",
    "dataset1['date'] = dataset1['Tweet Date'].dt.strftime('%d %b %Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_smsa =  dataset1[['date','Sentence','Sentiment']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29 Feb 2024</td>\n",
       "      <td>Gk muluk muluk, 100,000 lot saham BBCA aja</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29 Feb 2024</td>\n",
       "      <td>BCA Expoversary 2024 menawarkan promo suku bun...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29 Feb 2024</td>\n",
       "      <td>[USERNAME] saham bca nya menyusul ya ðŸ™‚</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29 Feb 2024</td>\n",
       "      <td>PT Bank BCA Syariah (BCA Syariah) turut memeri...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29 Feb 2024</td>\n",
       "      <td>[USERNAME] Begitu byk saham kamu memilih saham...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date                                           Sentence Sentiment\n",
       "0  29 Feb 2024         Gk muluk muluk, 100,000 lot saham BBCA aja  Positive\n",
       "1  29 Feb 2024  BCA Expoversary 2024 menawarkan promo suku bun...   Neutral\n",
       "2  29 Feb 2024             [USERNAME] saham bca nya menyusul ya ðŸ™‚  Positive\n",
       "3  29 Feb 2024  PT Bank BCA Syariah (BCA Syariah) turut memeri...   Neutral\n",
       "4  29 Feb 2024  [USERNAME] Begitu byk saham kamu memilih saham...  Positive"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_smsa.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0           Gk muluk muluk, 100,000 lot saham BBCA aja\n",
      "1    BCA Expoversary 2024 menawarkan promo suku bun...\n",
      "2               [USERNAME] saham bca nya menyusul ya ðŸ™‚\n",
      "3    PT Bank BCA Syariah (BCA Syariah) turut memeri...\n",
      "4    [USERNAME] Begitu byk saham kamu memilih saham...\n",
      "5    [USERNAME] Drpd bunga mending halÂ² yg berguna,...\n",
      "6    [USERNAME] [USERNAME] Pilihan RDN di Mirae Ass...\n",
      "7    [USERNAME] [USERNAME] pak buat sekuritas mirae...\n",
      "8                      [USERNAME] Bbca, soalnya stabil\n",
      "9    Menggelar pameran masih menjadi salah satu str...\n",
      "Name: Sentence, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data_smsa['Sentence'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/jupyter-23524010/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/jupyter-23524010/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Pastikan NLTK sudah mengunduh stopwords dan punktuasi\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import emoji\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Inisialisasi stop words untuk bahasa Indonesia\n",
    "stop_words = set(stopwords.words('indonesian'))\n",
    "\n",
    "def replace_emoji(text):\n",
    "    return emoji.demojize(text, delimiters=(\" \", \" \"))  # hasil: hello smiling_face\n",
    "\n",
    "# Fungsi pembersihan utama\n",
    "def clean_tweet(tweet):\n",
    "    tweet = tweet.lower()                                 # Lowercase\n",
    "    tweet = re.sub(r'\\[?username\\]?', '', tweet, flags=re.IGNORECASE)\n",
    "    tweet = replace_emoji(tweet)                          # Ganti emoji jadi teks\n",
    "    tweet = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', tweet) # Hapus URL\n",
    "    tweet = re.sub(r'@\\w+|#', '', tweet)                  # Hapus mention & hashtag\n",
    "    tweet = tweet.replace(\"hashtag\", \"\")                  # Hapus kata \"hashtag\"\n",
    "    tweet = re.sub(r'\\d+', '', tweet)                     # Hapus angka\n",
    "    tweet = re.sub(r'[^\\w\\s]', '', tweet)                 # Hapus tanda baca\n",
    "    tweet = re.sub(r'[^\\x00-\\x7F]+', '', tweet)           # Hapus karakter non-ASCII\n",
    "    tweet = re.sub(r'\\s+', ' ', tweet).strip()            # Hapus spasi berlebih\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1947466/1348316642.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_smsa['cleaned_Sentence'] = data_smsa['Sentence'].apply(clean_tweet)\n"
     ]
    }
   ],
   "source": [
    "data_smsa['cleaned_Sentence'] = data_smsa['Sentence'].apply(clean_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1947466/1522583709.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_smsa['date'] = pd.to_datetime(data_smsa['date'], format='%d %b %Y')\n"
     ]
    }
   ],
   "source": [
    "# Ubah kolom 'date' ke tipe datetime\n",
    "data_smsa['date'] = pd.to_datetime(data_smsa['date'], format='%d %b %Y')\n",
    "# Lakukan pengurutan berdasarkan tanggal (descending / terbaru dulu)\n",
    "data_smsa = data_smsa.sort_values(by='date', ascending=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>cleaned_Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-12-14</td>\n",
       "      <td>[HASHTAG] [HASHTAG] TOP loser by change: DSSA ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>top loser by change dssa rp poll rp tcpi rp tp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-12-17</td>\n",
       "      <td>[HASHTAG] [HASHTAG] TOP loser by change: ITMG ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>top loser by change itmg rp tcpi rp inkp rp tg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-12-18</td>\n",
       "      <td>Rapat Umum Pemegang Saham Luar Biasa (RUPSLB) ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>rapat umum pemegang saham luar biasa rupslb pt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-12</td>\n",
       "      <td>Saham big cap: BBCA, BBNI, BBRI, BMRI, TLKM na...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>saham big cap bbca bbni bbri bmri tlkm naik ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-25</td>\n",
       "      <td>Saham TPIA dan MEDC Masuk Indeks LQ45, Gantika...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>saham tpia dan medc masuk indeks lq gantikan s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date                                           Sentence Sentiment  \\\n",
       "0 2020-12-14  [HASHTAG] [HASHTAG] TOP loser by change: DSSA ...  Negative   \n",
       "1 2020-12-17  [HASHTAG] [HASHTAG] TOP loser by change: ITMG ...  Negative   \n",
       "2 2020-12-18  Rapat Umum Pemegang Saham Luar Biasa (RUPSLB) ...  Positive   \n",
       "3 2021-01-12  Saham big cap: BBCA, BBNI, BBRI, BMRI, TLKM na...  Positive   \n",
       "4 2021-01-25  Saham TPIA dan MEDC Masuk Indeks LQ45, Gantika...  Positive   \n",
       "\n",
       "                                    cleaned_Sentence  \n",
       "0  top loser by change dssa rp poll rp tcpi rp tp...  \n",
       "1  top loser by change itmg rp tcpi rp inkp rp tg...  \n",
       "2  rapat umum pemegang saham luar biasa rupslb pt...  \n",
       "3  saham big cap bbca bbni bbri bmri tlkm naik ha...  \n",
       "4  saham tpia dan medc masuk indeks lq gantikan s...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_smsa.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3288 entries, 0 to 3287\n",
      "Data columns (total 4 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   date              3288 non-null   datetime64[ns]\n",
      " 1   Sentence          3288 non-null   object        \n",
      " 2   Sentiment         3288 non-null   object        \n",
      " 3   cleaned_Sentence  3288 non-null   object        \n",
      "dtypes: datetime64[ns](1), object(3)\n",
      "memory usage: 102.9+ KB\n"
     ]
    }
   ],
   "source": [
    "data_smsa.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date                0\n",
      "Sentence            0\n",
      "Sentiment           0\n",
      "cleaned_Sentence    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data_smsa.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_smsa.to_csv('dataset/dataset_smsa_stok/data_clean/data_smsa_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tpia kembali kantongi restu pemegang saham untuk gelar rights issue url\n"
     ]
    }
   ],
   "source": [
    "# Menampilkan baris ke-16 dari kolom 'cleaned_tweet'\n",
    "print(data_smsa.loc[30, 'cleaned_Sentence'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_save_train_dataset1 = data_smsa[['cleaned_Sentence', 'Sentiment']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_save_train_dataset1.rename(columns={'cleaned_Sentence': 'text', 'Sentiment': 'sentiment'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_save_train_dataset1.to_csv('dataset/dataset_smsa_stok/data_clean/data_train/data_smsa.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3288 entries, 0 to 3287\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   text       3288 non-null   object\n",
      " 1   sentiment  3288 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 51.5+ KB\n"
     ]
    }
   ],
   "source": [
    "data_to_save_train_dataset1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPLIT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train1, valid1 = train_test_split(data_to_save_train_dataset1, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2630 entries, 2211 to 3174\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   text       2630 non-null   object\n",
      " 1   sentiment  2630 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 61.6+ KB\n"
     ]
    }
   ],
   "source": [
    "train1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "Positive    1429\n",
       "Negative     626\n",
       "Neutral      575\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 658 entries, 2212 to 436\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   text       658 non-null    object\n",
      " 1   sentiment  658 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 15.4+ KB\n"
     ]
    }
   ],
   "source": [
    "valid1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "Positive    340\n",
       "Negative    160\n",
       "Neutral     158\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid1['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1.to_csv('dataset/dataset_smsa_stok/data_clean/data_train/data_smsa_train.csv', index=False)\n",
    "valid1.to_csv('dataset/dataset_smsa_stok/data_clean/data_train/data_smsa_valid.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simpan file dalam format TSV (tab-separated)\n",
    "train1.to_csv('dataset/dataset_smsa_stok/data_clean/data_train/data_smsa_train.tsv', sep='\\t', index=False)\n",
    "valid1.to_csv('dataset/dataset_smsa_stok/data_clean/data_train/data_smsa_valid.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_path = './dataset/dataset_smsa_stok/data_clean/data_train/data_smsa_train.csv'\n",
    "valid_dataset_path = './dataset/dataset_smsa_stok/data_clean/data_train/data_smsa_valid.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_csv(train_dataset_path)\n",
    "y = pd.read_csv(valid_dataset_path)\n",
    "# z = pd.read_csv(test_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset NaN values:\n",
      "text         0\n",
      "sentiment    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Train dataset NaN values:\")\n",
    "print(x.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End Prepare Data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
